export LLMDBENCH_CONTROL_WORK_DIR=/tmp/cicd/
export LLMDBENCH_DEPLOY_MODEL_LIST="facebook/opt-125m"
export LLMDBENCH_VLLM_COMMON_NAMESPACE=llmdbenchcicd
export LLMDBENCH_HARNESS_NAMESPACE=llmdbenchcicd
#export LLMDBENCH_VLLM_COMMON_AFFINITY=nvidia.com/gpu.product:NVIDIA-L40S
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEMORY=48
export LLMDBENCH_VLLM_COMMON_PVC_STORAGE_CLASS=ocs-storagecluster-cephfs
export LLMDBENCH_VLLM_MODELSERVICE_RELEASE=llmdbenchcicd
export LLMDBENCH_VLLM_COMMON_REPLICAS=1

####export LLMDBENCH_VLLM_STANDALONE_IMAGE_REGISTRY=ghcr.io
####export LLMDBENCH_VLLM_STANDALONE_IMAGE_REPO=llm-d
####export LLMDBENCH_VLLM_STANDALONE_IMAGE_NAME=llm-d-inference-sim
####export LLMDBENCH_VLLM_STANDALONE_IMAGE_TAG=auto
####export LLMDBENCH_VLLM_COMMON_ACCELERATOR_NR=0
####export LLMDBENCH_VLLM_STANDALONE_ARGS="/app/llm-d-inference-sim____--model____/model-cache/models/REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL____--port____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_INFERENCE_PORT____--served-model-name____REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL"
####export LLMDBENCH_VLLM_COMMON_AFFINITY=kubernetes.io/os:linux
####export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM=0
####export LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM=0
####export LLMDBENCH_LLMD_IMAGE_NAME=llm-d-inference-sim
####export LLMDBENCH_VLLM_MODELSERVICE_DECODE_MODEL_COMMAND=imageDefault
####export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_MODEL_COMMAND=imageDefault
####export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_ARGS="[]"
####export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_ARGS="[]"

export LLMDBENCH_HARNESS_NAME=vllm-benchmark
export LLMDBENCH_HARNESS_EXPERIMENT_PROFILE=sanity_random.yaml
