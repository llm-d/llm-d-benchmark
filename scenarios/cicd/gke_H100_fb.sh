export LLMDBENCH_CONTROL_WORK_DIR=/tmp/cicd/
export LLMDBENCH_DEPLOY_MODEL_LIST="meta-llama/Llama-3.2-1B"
export LLMDBENCH_VLLM_COMMON_NAMESPACE=llmdbenchcicd
export LLMDBENCH_HARNESS_NAMESPACE=llmdbenchcicd
export LLMDBENCH_VLLM_COMMON_AFFINITY=cloud.google.com/gke-accelerator:nvidia-h100-80gb
export LLMDBENCH_VLLM_COMMON_PVC_STORAGE_CLASS=standard-rwx
export LLMDBENCH_VLLM_COMMON_PVC_MODEL_CACHE_SIZE=1Ti
export LLMDBENCH_VLLM_MODELSERVICE_RELEASE=llmdbenchcicd
export LLMDBENCH_VLLM_COMMON_REPLICAS=1
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_NR=1
export LLMDBENCH_HARNESS_NAME=inference-perf
export LLMDBENCH_HARNESS_EXPERIMENT_PROFILE=sanity_random.yaml
export _LD_LIBRARY_PATH="\${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64"
export LLMDBENCH_VLLM_COMMON_ENVVARS_TO_YAML=LLMDBENCH_VLLM_STANDALONE_VLLM_ALLOW_LONG_MAX_MODEL_LEN,LLMDBENCH_VLLM_STANDALONE_VLLM_SERVER_DEV_MODE,_LD_LIBRARY_PATH
