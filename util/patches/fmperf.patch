diff --git a/fmperf/Cluster.py b/fmperf/Cluster.py
index 5a398f9..fb616af 100644
--- a/fmperf/Cluster.py
+++ b/fmperf/Cluster.py
@@ -40,8 +40,7 @@ def __init__(
         self.security_context = {
             "allowPrivilegeEscalation": False,
             "capabilities": {"drop": ["ALL"]},
-            "runAsNonRoot": False,
-            "runAsUser": 0,
+            "runAsNonRoot": True,
             "seccompProfile": {"type": "RuntimeDefault"},
         }
 
@@ -412,6 +411,26 @@ def evaluate(
             # Add OUTPUT_PATH based on the volume mount and job name
             env.append({"name": "OUTPUT_PATH", "value": f"/requests/{job_name}"})
 
+            # Add HF_TOKEN from host environment if available
+            hf_token = (
+                os.environ.get("HF_TOKEN")
+                or os.environ.get("HUGGINGFACE_TOKEN")
+                or os.environ.get("hf_token")
+                or os.environ.get("huggingface_token")
+            )
+            if hf_token:
+                env.append({"name": "HF_TOKEN", "value": hf_token})
+            elif os.environ.get("HF_TOKEN_SECRET"):
+                # Use specified secret name if provided
+                env.append({
+                    "name": "HF_TOKEN",
+                    "valueFrom": {
+                        "secretKeyRef": {
+                            "name": os.environ.get("HF_TOKEN_SECRET"),
+                            "key": "HF_TOKEN"
+                        }
+                    }
+                })
             # Add Hugging Face cache environment variables
             env.extend(
                 [
@@ -423,6 +442,12 @@ def evaluate(
                     },
                 ]
             )
+            container_name = "guidellm-benchmark"
+            container_args = []  # Use default entrypoint
+        elif isinstance(workload.spec, LMBenchmarkWorkload):
+            # Use the environment variables from LMBenchmarkWorkload
+            env = workload.spec.get_env(target, model, workload.file)
+            job_name = f"lmbenchmark-evaluate{'-'+id if id else ''}"
 
             # Add HF_TOKEN from host environment if available
             hf_token = (
@@ -433,14 +458,17 @@ def evaluate(
             )
             if hf_token:
                 env.append({"name": "HF_TOKEN", "value": hf_token})
-
-            container_name = "guidellm-benchmark"
-            container_args = []  # Use default entrypoint
-        elif isinstance(workload.spec, LMBenchmarkWorkload):
-            # Use the environment variables from LMBenchmarkWorkload
-            env = workload.spec.get_env(target, model, workload.file)
-            job_name = f"lmbenchmark-evaluate{'-'+id if id else ''}"
-
+            elif os.environ.get("HF_TOKEN_SECRET"):
+                # Use specified secret name if provided
+                env.append({
+                    "name": "HF_TOKEN",
+                    "valueFrom": {
+                        "secretKeyRef": {
+                            "name": os.environ.get("HF_TOKEN_SECRET"),
+                            "key": "HF_TOKEN"
+                        }
+                    }
+                })
             # Add Hugging Face cache environment variables
             env.extend(
                 [
@@ -452,23 +480,15 @@ def evaluate(
                     },
                 ]
             )
-
-            # Add HF_TOKEN from host environment if available
-            hf_token = (
-                os.environ.get("HF_TOKEN")
-                or os.environ.get("HUGGINGFACE_TOKEN")
-                or os.environ.get("hf_token")
-                or os.environ.get("huggingface_token")
-            )
-            if hf_token:
-                env.append({"name": "HF_TOKEN", "value": hf_token})
-
             container_name = "lmbenchmark"
             container_args = [
                 "QPS_VALUES=($(env | grep QPS_VALUES_ | sort -V | cut -d= -f2)); "
-                ". ~/.bashrc && . .venv/bin/activate && "
+                ". .venv/bin/activate && "
                 '/app/run_benchmarks.sh "$MODEL" "$BASE_URL" "$SAVE_FILE_KEY" "$SCENARIOS" "${QPS_VALUES[@]}"'
             ]
+            # Add bashrc loading only if .bashrc exists
+            if os.path.exists(os.path.expanduser("~/.bashrc")):
+                container_args[1] = ". ~/.bashrc && " + container_args[1]
         else:
             env = [
                 {"name": "MODEL_ID", "value": model_name},
@@ -524,16 +544,17 @@ def evaluate(
                         "initContainers": [
                             {
                                 "name": "init-cache-dirs",
-                                "image": "busybox",
+                                "image": "registry.access.redhat.com/ubi9-minimal",
                                 "command": [
                                     "sh",
                                     "-c",
-                                    "mkdir -p /requests/hf_cache/datasets && FOLDER_NAME=$(echo $SAVE_FILE_KEY | sed 's|/requests/||' | sed 's|/LMBench||') && mkdir -p /requests/$FOLDER_NAME && chmod -R 777 /requests && ls -la /requests",
+                                    "mkdir -p /requests/hf_cache/datasets && FOLDER_NAME=$(echo $SAVE_FILE_KEY | sed 's|/requests/||' | sed 's|/LMBench||') && mkdir -p /requests/$FOLDER_NAME && ls -la /requests",
                                 ],
                                 "volumeMounts": [
                                     {"name": "requests", "mountPath": "/requests"}
                                 ],
                                 "env": env,
+                                "securityContext": self.security_context,
                             }
                         ],
                         "containers": [
@@ -547,10 +568,7 @@ def evaluate(
                                 ),
                                 "args": container_args,
                                 "volumeMounts": volume_mounts,
-                                "securityContext": {
-                                    "allowPrivilegeEscalation": False,
-                                    "capabilities": {"drop": ["ALL"]},
-                                },
+                                "securityContext": self.security_context,
                             }
                         ],
                         "restartPolicy": "Never",
@@ -642,6 +660,6 @@ def evaluate(
         else:
             perf_out, energy_out = None, None
 
-        deleting.delete_namespaced_job(job_name, self.namespace)
+        #deleting.delete_namespaced_job(job_name, self.namespace)
 
         return perf_out, energy_out
