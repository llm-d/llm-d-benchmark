standup:
  - stack: "stack-1"
    parameters:
      model:
        - name: meta-llama/Llama-3.1-8B-Instruct
          maxlen: 16384
      volumes:
        - name: model-storage
          size: 1Ti
      replicas:
        decode: 2
        prefill: 0
      command:
        decode:
          type: vllmServe
          args:
            - "--enforce-eager"
            - "--block-size"
            - ".standup[0].parameters.model[0].blocksize"
            - "--kv-transfer-config"
            - '{"kv_connector":"NixlConnector","kv_role":"kv_both"}'
            - "--disable-log-requests"
            - "--disable-uvicorn-access-log"
            - "--max-model-len"
            - ".standup[0].parameters.model[0].maxlen"
harness:
  - runner: "runner-1"
    parameters:
      profile: shared_prefix_synthetic.yaml