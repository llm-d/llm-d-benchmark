# Shared configuration and validation

export LLMDBENCH_CONTROL_USERNAME=${LLMDBENCH_CONTROL_USERNAME:-$(id -un)}

# Cluster access
export LLMDBENCH_CLUSTER_URL="${LLMDBENCH_CLUSTER_URL:-auto}"
export LLMDBENCH_CLUSTER_TOKEN="${LLMDBENCH_CLUSTER_TOKEN:-sha256~sVYh-xxx}"

export LLMDBENCH_HF_TOKEN="${LLMDBENCH_HF_TOKEN:-}"

# Images
export LLMDBENCH_IMAGE_REGISTRY=${LLMDBENCH_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_IMAGE_REPO=${LLMDBENCH_IMAGE_REPO:-llm-d}
export LLMDBENCH_IMAGE_NAME=${LLMDBENCH_IMAGE_NAME:-llm-d-benchmark}
export LLMDBENCH_IMAGE_TAG=${LLMDBENCH_IMAGE_TAG:-auto}
export LLMDBENCH_LLMD_IMAGE_REGISTRY=${LLMDBENCH_LLMD_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_LLMD_IMAGE_REPO=${LLMDBENCH_LLMD_IMAGE_REPO:-llm-d}
export LLMDBENCH_LLMD_IMAGE_NAME=${LLMDBENCH_LLMD_IMAGE_NAME:-llm-d-cuda}
export LLMDBENCH_LLMD_IMAGE_TAG=${LLMDBENCH_LLMD_IMAGE_TAG:-auto}
export LLMDBENCH_LLMD_MODELSERVICE_IMAGE_REGISTRY=${LLMDBENCH_LLMD_MODELSERVICE_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_LLMD_MODELSERVICE_IMAGE_REPO=${LLMDBENCH_LLMD_MODELSERVICE_IMAGE_REPO:-llm-d}
export LLMDBENCH_LLMD_MODELSERVICE_IMAGE_NAME=${LLMDBENCH_LLMD_MODELSERVICE_IMAGE_NAME:-llm-d-model-service}
export LLMDBENCH_LLMD_MODELSERVICE_IMAGE_TAG=${LLMDBENCH_LLMD_MODELSERVICE_IMAGE_TAG:-auto}
export LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_REGISTRY=${LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_REPO=${LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_REPO:-llm-d}
export LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_NAME=${LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_NAME:-llm-d-inference-scheduler}
export LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_TAG=${LLMDBENCH_LLMD_INFERENCESCHEDULER_IMAGE_TAG:-auto}
export LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_REGISTRY=${LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_REPO=${LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_REPO:-llm-d}
export LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_NAME=${LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_NAME:-llm-d-routing-sidecar}
export LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_TAG=${LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_TAG:-auto}
export LLMDBENCH_LLMD_INFERENCESIM_IMAGE_REGISTRY=${LLMDBENCH_LLMD_INFERENCESIM_IMAGE_REGISTRY:-ghcr.io}
export LLMDBENCH_LLMD_INFERENCESIM_IMAGE_REPO=${LLMDBENCH_LLMD_INFERENCESIM_IMAGE_REPO:-llm-d}
export LLMDBENCH_LLMD_INFERENCESIM_IMAGE_NAME=${LLMDBENCH_LLMD_INFERENCESIM_IMAGE_NAME:-llm-d-inference-sim}
export LLMDBENCH_LLMD_INFERENCESIM_IMAGE_TAG=${LLMDBENCH_LLMD_INFERENCESIM_IMAGE_TAG:-auto}
export LLMDBENCH_VLLM_STANDALONE_IMAGE_REGISTRY=${LLMDBENCH_VLLM_STANDALONE_IMAGE_REGISTRY:-docker.io}
export LLMDBENCH_VLLM_STANDALONE_IMAGE_REPO=${LLMDBENCH_VLLM_STANDALONE_IMAGE_REPO:-vllm}
export LLMDBENCH_VLLM_STANDALONE_IMAGE_NAME=${LLMDBENCH_VLLM_STANDALONE_IMAGE_NAME:-vllm-openai}
export LLMDBENCH_VLLM_STANDALONE_IMAGE_TAG=${LLMDBENCH_VLLM_STANDALONE_IMAGE_TAG:-latest}

# External repositories
export LLMDBENCH_HARNESS_GIT_REPO="${LLMDBENCH_HARNESS_GIT_REPO:-auto}"
export LLMDBENCH_HARNESS_DIR="${LLMDBENCH_HARNESS_DIR:-/tmp}"
export LLMDBENCH_HARNESS_GIT_BRANCH="${LLMDBENCH_HARNESS_GIT_BRANCH:-main}"

# WVA and Monioring Service
export LLMDBENCH_WVA_WELL_LIT_PATH="${LLMDBENCH_WVA_WELL_LIT_PATH:-inference-scheduling}"
export LLMDBENCH_WVA_NAMESPACE="${LLMDBENCH_WVA_NAMESPACE:-workload-variant-autoscaler-system}"
export LLMDBENCH_WVA_ENABLED="${LLMDBENCH_WVA_ENABLED:-0}"
export LLMDBENCH_WVA_HELM_REPOSITORY_URL=${LLMDBENCH_WVA_HELM_REPOSITORY_URL:-"oci://ghcr.io/llm-d/workload-variant-autoscaler"}
export LLMDBENCH_WVA_CHART_VERSION="${LLMDBENCH_WVA_CHART_VERSION:-0.1.0}"
export LLMDBENCH_OPENSHIFT_USER_WORKLOAD_MONITORING_NS="${LLMDBENCH_OPENSHIFT_USER_WORKLOAD_MONITORING_NS:-openshift-user-workload-monitoring}"

# WVA Configuration
export LLMDBENCH_WVA_ENABLED="${LLMDBENCH_WVA_ENABLED:-True}"
export LLMDBENCH_WVA_IMAGE_REPOSITORY="${LLMDBENCH_WVA_IMAGE_REPOSITORY:-ghcr.io/llm-d/workload-variant-autoscaler}"
export LLMDBENCH_WVA_IMAGE_TAG="${LLMDBENCH_WVA_IMAGE_TAG:-v0.0.1}"
export LLMDBENCH_WVA_WELL_LIT_PATH="${LLMDBENCH_WVA_WELL_LIT_PATH:-workload-variant-autoscaler}"
export LLMDBENCH_WVA_REPLICA_COUNT="${LLMDBENCH_WVA_REPLICA_COUNT:-1}"

# WVA Metrics
export LLMDBENCH_WVA_METRICS_ENABLED="${LLMDBENCH_WVA_METRICS_ENABLED:-True}"
export LLMDBENCH_WVA_METRICS_PORT="${LLMDBENCH_WVA_METRICS_PORT:-8443}"
export LLMDBENCH_WVA_METRICS_SECURE="${LLMDBENCH_WVA_METRICS_SECURE:-True}"

# WVA Prometheus
export LLMDBENCH_OPENSHIFT_USER_WORKLOAD_MONITORING_NS="${LLMDBENCH_OPENSHIFT_USER_WORKLOAD_MONITORING_NS:-openshift-user-workload-monitoring}"
export LLMDBENCH_WVA_PROM_BASE_URL="${LLMDBENCH_WVA_PROM_BASE_URL:-https://thanos-querier.openshift-monitoring.svc.cluster.local}"
export LLMDBENCH_WVA_PROM_BASE_URL_PORT="${LLMDBENCH_WVA_PROM_BASE_URL_PORT:-9091}"

# WVA Variant Autoscaling
export LLMDBENCH_WVA_VARIANT_AUTOSCALING_ENABLED="${LLMDBENCH_VARIANT_AUTOSCALING_ENABLED:-True}"
export LLMDBENCH_WVA_VARIANT_AUTOSCALING_SLO_TPOT="${LLMDBENCH_VARIANT_AUTOSCALING_SLO_TPOT:-30}"
export LLMDBENCH_WVA_VARIANT_AUTOSCALING_SLO_TTFT="${LLMDBENCH_VARIANT_AUTOSCALING_SLO_TTFT:-1000}"

# WVA Horizontal Pod Autoscaler
export LLMDBENCH_WVA_HPA_ENABLED="${LLMDBENCH_HPA_ENABLED:-True}"
export LLMDBENCH_WVA_HPA_MAX_REPLICAS="${LLMDBENCH_HPA_MAX_REPLICAS:-10}"
export LLMDBENCH_WVA_HPA_TARGET_AVG_VALUE="${LLMDBENCH_HPA_TARGET_AVG_VALUE:-1}"

# WVA VLLM Service
export LLMDBENCH_WVA_VLLM_SERVICE_ENABLED="${LLMDBENCH_WVA_VLLM_SERVICE_ENABLED:-True}"
export LLMDBENCH_WVA_VLLM_SERVICE_NODE_PORT_MIN="${LLMDBENCH_WVA_VLLM_SERVICE_NODE_PORT_MIN:-30000}"
export LLMDBENCH_WVA_VLLM_SERVICE_NODE_PORT_MAX="${LLMDBENCH_WVA_VLLM_SERVICE_NODE_PORT_MAX:-32767}"
export LLMDBENCH_WVA_VLLM_SERVICE_INTERVAL="${LLMDBENCH_WVA_VLLM_SERVICE_INTERVAL:-15s}"

# LLM-D-Benchmark deployment specific variables
export LLMDBENCH_DEPLOY_MODEL_LIST=${LLMDBENCH_DEPLOY_MODEL_LIST:-"facebook/opt-125m"}
export LLMDBENCH_DEPLOY_METHODS=${LLMDBENCH_DEPLOY_METHODS:-"modelservice"}

# Gateway provider specific variables
export LLMDBENCH_GATEWAY_PROVIDER_KGATEWAY_HELM_REPOSITORY_URL=${LLMDBENCH_GATEWAY_PROVIDER_KGATEWAY_HELM_REPOSITORY_URL:-"oci://cr.kgateway.dev/kgateway-dev/charts"}
export LLMDBENCH_GATEWAY_PROVIDER_KGATEWAY_CHART_VERSION=${LLMDBENCH_GATEWAY_PROVIDER_KGATEWAY_CHART_VERSION:-"v2.0.3"}
export LLMDBENCH_GATEWAY_PROVIDER_ISTIO_HELM_REPOSITORY_URL=${LLMDBENCH_GATEWAY_PROVIDER_ISTIO_HELM_REPOSITORY_URL:-"oci://gcr.io/istio-testing/charts"}
export LLMDBENCH_GATEWAY_PROVIDER_ISTIO_CHART_VERSION=${LLMDBENCH_GATEWAY_PROVIDER_ISTIO_CHART_VERSION:-"1.28-alpha.89f30b26ba71bf5e538083a4720d0bc2d8c06401"}

# Applicable to both standalone and modelservice
export LLMDBENCH_IGNORE_FAILED_VALIDATION="${LLMDBENCH_IGNORE_FAILED_VALIDATION:-true}"    # default is to continue deployment if validation fails
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEMORY="${LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEMORY:-auto}"
export LLMDBENCH_VLLM_COMMON_NAMESPACE="${LLMDBENCH_VLLM_COMMON_NAMESPACE:-llmdbench}"
export LLMDBENCH_VLLM_COMMON_SERVICE_ACCOUNT="${LLMDBENCH_VLLM_COMMON_SERVICE_ACCOUNT:-default}"

export LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_RESOURCE=${LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_RESOURCE:-}
export LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_NR=${LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_NR:-}
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_RESOURCE=${LLMDBENCH_VLLM_COMMON_ACCELERATOR_RESOURCE:-auto}
export LLMDBENCH_VLLM_COMMON_NETWORK_RESOURCE=${LLMDBENCH_VLLM_COMMON_NETWORK_RESOURCE:-}
export LLMDBENCH_VLLM_COMMON_NETWORK_NR=${LLMDBENCH_VLLM_COMMON_NETWORK_NR:-}
export LLMDBENCH_VLLM_COMMON_AFFINITY=${LLMDBENCH_VLLM_COMMON_AFFINITY:-auto}
export LLMDBENCH_VLLM_COMMON_REPLICAS=${LLMDBENCH_VLLM_COMMON_REPLICAS:-1}
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_NR=${LLMDBENCH_VLLM_COMMON_ACCELERATOR_NR:-auto}
export LLMDBENCH_VLLM_COMMON_TENSOR_PARALLELISM=${LLMDBENCH_VLLM_COMMON_TENSOR_PARALLELISM:-1}
export LLMDBENCH_VLLM_COMMON_DATA_PARALLELISM=${LLMDBENCH_VLLM_COMMON_DATA_PARALLELISM:-1}
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEM_UTIL=${LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEM_UTIL:-0.95}
export LLMDBENCH_VLLM_COMMON_CPU_NR=${LLMDBENCH_VLLM_COMMON_CPU_NR:-4}
export LLMDBENCH_VLLM_COMMON_CPU_MEM=${LLMDBENCH_VLLM_COMMON_CPU_MEM:-40Gi}
export LLMDBENCH_VLLM_COMMON_SHM_MEM=${LLMDBENCH_VLLM_COMMON_SHM_MEM:-16Gi}

export LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN=${LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN:-16384}
export LLMDBENCH_VLLM_COMMON_BLOCK_SIZE=${LLMDBENCH_VLLM_COMMON_BLOCK_SIZE:-64}
export LLMDBENCH_VLLM_COMMON_MAX_NUM_BATCHED_TOKENS=${LLMDBENCH_VLLM_COMMON_MAX_NUM_BATCHED_TOKENS:-4096}
export LLMDBENCH_VLLM_COMMON_PVC_NAME=${LLMDBENCH_VLLM_COMMON_PVC_NAME:-"model-pvc"}
export LLMDBENCH_VLLM_COMMON_PVC_MODEL_CACHE_SIZE="${LLMDBENCH_VLLM_COMMON_PVC_MODEL_CACHE_SIZE:-300Gi}"
export LLMDBENCH_VLLM_COMMON_EXTRA_PVC_NAME=${LLMDBENCH_VLLM_COMMON_EXTRA_PVC_NAME:-}
export LLMDBENCH_VLLM_COMMON_EXTRA_PVC_SIZE="${LLMDBENCH_VLLM_COMMON_EXTRA_PVC_SIZE:-10Gi}"
export LLMDBENCH_VLLM_COMMON_PVC_STORAGE_CLASS="${LLMDBENCH_VLLM_COMMON_PVC_STORAGE_CLASS:-default}"
export LLMDBENCH_VLLM_COMMON_PVC_DOWNLOAD_TIMEOUT=${LLMDBENCH_VLLM_COMMON_PVC_DOWNLOAD_TIMEOUT:-"2400"}
export LLMDBENCH_VLLM_COMMON_HF_TOKEN_KEY="${LLMDBENCH_VLLM_COMMON_HF_TOKEN_KEY:-"HF_TOKEN"}"
export LLMDBENCH_VLLM_COMMON_HF_TOKEN_NAME=${LLMDBENCH_VLLM_COMMON_HF_TOKEN_NAME:-"llm-d-hf-token"}
export LLMDBENCH_VLLM_COMMON_FQDN=${LLMDBENCH_VLLM_COMMON_FQDN:-".svc.cluster.local"}
export LLMDBENCH_VLLM_COMMON_TIMEOUT=${LLMDBENCH_VLLM_COMMON_TIMEOUT:-3600}
export LLMDBENCH_VLLM_COMMON_INFERENCE_PORT=${LLMDBENCH_VLLM_COMMON_INFERENCE_PORT:-"8000"}
export LLMDBENCH_VLLM_COMMON_METRICS_PORT=${LLMDBENCH_VLLM_COMMON_METRICS_PORT:-"8200"}
export LLMDBENCH_VLLM_COMMON_NIXL_SIDE_CHANNEL_PORT=${LLMDBENCH_VLLM_COMMON_NIXL_SIDE_CHANNEL_PORT:-"5557"}
export LLMDBENCH_VLLM_COMMON_ANNOTATIONS=${LLMDBENCH_VLLM_COMMON_ANNOTATIONS:-deployed-by:$LLMDBENCH_CONTROL_USERNAME,modelservice:llm-d-benchmark}
export LLMDBENCH_VLLM_COMMON_ENVVARS_TO_YAML=${LLMDBENCH_VLLM_COMMON_ENVVARS_TO_YAML:-LLMDBENCH_VLLM_STANDALONE_VLLM_ALLOW_LONG_MAX_MODEL_LEN,LLMDBENCH_VLLM_STANDALONE_VLLM_SERVER_DEV_MODE}
export LLMDBENCH_VLLM_COMMON_INITIAL_DELAY_PROBE=${LLMDBENCH_VLLM_COMMON_INITIAL_DELAY_PROBE:-30}
export LLMDBENCH_VLLM_COMMON_POD_SCHEDULER=${LLMDBENCH_VLLM_COMMON_POD_SCHEDULER:-"default-scheduler"}
export LLMDBENCH_VLLM_COMMON_EXTRA_POD_CONFIG=${LLMDBENCH_VLLM_COMMON_EXTRA_POD_CONFIG:-"#noconfig"}
export LLMDBENCH_VLLM_COMMON_EXTRA_CONTAINER_CONFIG=${LLMDBENCH_VLLM_COMMON_EXTRA_CONTAINER_CONFIG:-"#noconfig"}
export LLMDBENCH_VLLM_COMMON_EXTRA_VOLUME_MOUNTS=${LLMDBENCH_VLLM_COMMON_EXTRA_VOLUME_MOUNTS:-"#noconfig"}
export LLMDBENCH_VLLM_COMMON_EXTRA_VOLUMES=${LLMDBENCH_VLLM_COMMON_EXTRA_VOLUMES:-"#noconfig"}

# Standalone-specific parameters
export LLMDBENCH_VLLM_STANDALONE_MODEL_LOADER_EXTRA_CONFIG=${LLMDBENCH_VLLM_STANDALONE_MODEL_LOADER_EXTRA_CONFIG:-"{}"}
export LLMDBENCH_VLLM_STANDALONE_VLLM_LOGGING_LEVEL=${LLMDBENCH_VLLM_STANDALONE_VLLM_LOGGING_LEVEL:-INFO}
export LLMDBENCH_VLLM_STANDALONE_PVC_MOUNTPOINT=${LLMDBENCH_VLLM_STANDALONE_PVC_MOUNTPOINT:-/model-storage}
export LLMDBENCH_VLLM_STANDALONE_PREPROCESS=${LLMDBENCH_VLLM_STANDALONE_PREPROCESS:-true}
export LLMDBENCH_VLLM_STANDALONE_ROUTE=${LLMDBENCH_VLLM_STANDALONE_ROUTE:-1}
export LLMDBENCH_VLLM_STANDALONE_HTTPROUTE=${LLMDBENCH_VLLM_STANDALONE_HTTPROUTE:-0}
export LLMDBENCH_VLLM_STANDALONE_VLLM_ALLOW_LONG_MAX_MODEL_LEN=${LLMDBENCH_VLLM_STANDALONE_VLLM_ALLOW_LONG_MAX_MODEL_LEN:-1}
# VLLM_SERVER_DEV_MODE="1" necessary to enable sleep/wake_up server endpoints
export LLMDBENCH_VLLM_STANDALONE_VLLM_SERVER_DEV_MODE=${LLMDBENCH_VLLM_STANDALONE_VLLM_SERVER_DEV_MODE:-1}
export LLMDBENCH_VLLM_STANDALONE_VLLM_LOAD_FORMAT=${LLMDBENCH_VLLM_STANDALONE_VLLM_LOAD_FORMAT:-"auto"}
export LLMDBENCH_VLLM_STANDALONE_ARGS=${LLMDBENCH_VLLM_STANDALONE_ARGS:-"REPLACE_ENV_LLMDBENCH_VLLM_STANDALONE_PREPROCESS____;____vllm____serve____REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL____--enable-sleep-mode____--load-format____REPLACE_ENV_LLMDBENCH_VLLM_STANDALONE_VLLM_LOAD_FORMAT____--port____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_INFERENCE_PORT____--max-model-len____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN____--disable-log-requests____--gpu-memory-utilization____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEM_UTIL____--tensor-parallel-size____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_TENSOR_PARALLELISM____--model-loader-extra-config____\"\$LLMDBENCH_VLLM_STANDALONE_MODEL_LOADER_EXTRA_CONFIG\""}
export LLMDBENCH_VLLM_STANDALONE_EPHEMERAL_STORAGE=${LLMDBENCH_VLLM_STANDALONE_EPHEMERAL_STORAGE:-"20Gi"}

# Modelservice (helm chart) specific parameters
export LLMDBENCH_VLLM_INFRA_CHART_NAME=${LLMDBENCH_VLLM_INFRA_CHART_NAME:-"llm-d-infra"}
export LLMDBENCH_VLLM_INFRA_CHART_VERSION=${LLMDBENCH_VLLM_INFRA_CHART_VERSION:-v1.3.0}
export LLMDBENCH_VLLM_INFRA_HELM_REPOSITORY=${LLMDBENCH_VLLM_INFRA_HELM_REPOSITORY:-"llm-d-infra"}
export LLMDBENCH_VLLM_INFRA_HELM_REPOSITORY_URL=${LLMDBENCH_VLLM_INFRA_HELM_REPOSITORY_URL:-"https://llm-d-incubation.github.io/${LLMDBENCH_VLLM_INFRA_CHART_NAME}/"}
export LLMDBENCH_VLLM_GAIE_CHART_NAME=${LLMDBENCH_VLLM_GAIE_CHART_NAME:-oci://registry.k8s.io/gateway-api-inference-extension/charts/inferencepool}
#FIXME: oci helm repos do not output a list of versions. Use "skopeo list-tags  docker://registry.k8s.io/gateway-api-inference-extension/charts/inferencepool"
export LLMDBENCH_VLLM_GAIE_CHART_VERSION=${LLMDBENCH_VLLM_GAIE_CHART_VERSION:-v1.0.1}
#export LLMDBENCH_VLLM_GAIE_CHART_VERSION=${LLMDBENCH_VLLM_GAIE_CHART_VERSION:-v0.5.1}

# Gateway API and GAIE CRD versions
export LLMDBENCH_GATEWAY_API_CRD_REVISION=${LLMDBENCH_GATEWAY_API_CRD_REVISION:-"v1.3.0"}
export LLMDBENCH_GATEWAY_API_INFERENCE_EXTENSION_CRD_REVISION=${LLMDBENCH_GATEWAY_API_INFERENCE_EXTENSION_CRD_REVISION:-$LLMDBENCH_VLLM_GAIE_CHART_VERSION}

export LLMDBENCH_VLLM_MODELSERVICE_RELEASE=${LLMDBENCH_VLLM_MODELSERVICE_RELEASE:-"llmdbench"}
export LLMDBENCH_VLLM_MODELSERVICE_VALUES_FILE=${LLMDBENCH_VLLM_MODELSERVICE_VALUES_FILE:-"default-values.yaml"}
export LLMDBENCH_VLLM_MODELSERVICE_ADDITIONAL_SETS=${LLMDBENCH_VLLM_MODELSERVICE_ADDITIONAL_SETS:-""}
export LLMDBENCH_VLLM_MODELSERVICE_CHART_VERSION=${LLMDBENCH_VLLM_MODELSERVICE_CHART_VERSION:-v0.2.16}
export LLMDBENCH_VLLM_MODELSERVICE_CHART_NAME=${LLMDBENCH_VLLM_MODELSERVICE_CHART_NAME:-"llm-d-modelservice"}
export LLMDBENCH_VLLM_MODELSERVICE_HELM_REPOSITORY=${LLMDBENCH_VLLM_MODELSERVICE_HELM_REPOSITORY:-"llm-d-modelservice"}
export LLMDBENCH_VLLM_MODELSERVICE_HELM_REPOSITORY_URL=${LLMDBENCH_VLLM_MODELSERVICE_HELM_REPOSITORY_URL:-"https://llm-d-incubation.github.io/llm-d-modelservice/"}
export LLMDBENCH_VLLM_MODELSERVICE_URI_PROTOCOL=${LLMDBENCH_VLLM_MODELSERVICE_URI_PROTOCOL:-"pvc"}
export LLMDBENCH_VLLM_MODELSERVICE_GATEWAY_CLASS_NAME=${LLMDBENCH_VLLM_MODELSERVICE_GATEWAY_CLASS_NAME:-kgateway}
export LLMDBENCH_VLLM_MODELSERVICE_ROUTE=${LLMDBENCH_VLLM_MODELSERVICE_ROUTE:-true}
export LLMDBENCH_VLLM_MODELSERVICE_EPP=${LLMDBENCH_VLLM_MODELSERVICE_EPP:-false}
export LLMDBENCH_VLLM_MODELSERVICE_INFERENCE_POOL=${LLMDBENCH_VLLM_MODELSERVICE_INFERENCE_POOL:-false}
# Endpoint Picker Parameters
export LLMDBENCH_VLLM_MODELSERVICE_GAIE_PLUGINS_CONFIGFILE=${LLMDBENCH_VLLM_MODELSERVICE_GAIE_PLUGINS_CONFIGFILE:-"default-plugins.yaml"}

export LLMDBENCH_LLMD_ROUTINGSIDECAR_CONNECTOR=${LLMDBENCH_LLMD_ROUTINGSIDECAR_CONNECTOR:-"nixlv2"}
export LLMDBENCH_LLMD_ROUTINGSIDECAR_DEBUG_LEVEL=${LLMDBENCH_LLMD_ROUTINGSIDECAR_DEBUG_LEVEL:-3}

# Harness and Experiment
export LLMDBENCH_HARNESS_PROFILE_HARNESS_LIST=$(ls ${LLMDBENCH_MAIN_DIR}/workload/profiles/)
export LLMDBENCH_HARNESS_NAME=${LLMDBENCH_HARNESS_NAME:-inference-perf}
export LLMDBENCH_HARNESS_EXPERIMENT_PROFILE="${LLMDBENCH_HARNESS_EXPERIMENT_PROFILE:-sanity_random.yaml}"
export LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS=${LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS:-}
export LLMDBENCH_HARNESS_EXPERIMENT_PROFILE_OVERRIDES=${LLMDBENCH_HARNESS_EXPERIMENT_PROFILE_OVERRIDES:-}
export LLMDBENCH_HARNESS_EXECUTABLE=${LLMDBENCH_HARNESS_EXECUTABLE:-llm-d-benchmark.sh}
export LLMDBENCH_HARNESS_CONDA_ENV_NAME="${LLMDBENCH_HARNESS_CONDA_ENV_NAME:-${LLMDBENCH_HARNESS_NAME}-env}"
export LLMDBENCH_HARNESS_WAIT_TIMEOUT=${LLMDBENCH_HARNESS_WAIT_TIMEOUT:-3600}
export LLMDBENCH_HARNESS_CPU_NR=${LLMDBENCH_HARNESS_CPU_NR:-16}
export LLMDBENCH_HARNESS_CPU_MEM=${LLMDBENCH_HARNESS_CPU_MEM:-32Gi}
export LLMDBENCH_HARNESS_NAMESPACE=${LLMDBENCH_HARNESS_NAMESPACE:-llmdbench}
export LLMDBENCH_HARNESS_SERVICE_ACCOUNT=${LLMDBENCH_HARNESS_SERVICE_ACCOUNT:-${LLMDBENCH_HARNESS_NAME}-runner}
export LLMDBENCH_HARNESS_PVC_NAME="${LLMDBENCH_HARNESS_PVC_NAME:-"workload-pvc"}"
export LLMDBENCH_HARNESS_PVC_SIZE="${LLMDBENCH_HARNESS_PVC_SIZE:-20Gi}"
export LLMDBENCH_HARNESS_CONTAINER_IMAGE=${LLMDBENCH_HARNESS_CONTAINER_IMAGE:-lmcache/lmcache-benchmark:main}
export LLMDBENCH_HARNESS_SKIP_RUN=${LLMDBENCH_HARNESS_SKIP_RUN:-}
export LLMDBENCH_HARNESS_ENVVARS_TO_YAML=${LLMDBENCH_HARNESS_ENVVARS_TO_YAML:-LLMDBENCH_RUN_EXPERIMENT}

export LLMDBENCH_RUN_EXPERIMENT_ID=${LLMDBENCH_RUN_EXPERIMENT_ID:-$(date +%s)}
export LLMDBENCH_RUN_EXPERIMENT_RESULTS_DIR_PREFIX=${LLMDBENCH_RUN_EXPERIMENT_RESULTS_DIR_PREFIX:-/requests}
export LLMDBENCH_RUN_EXPERIMENT_ANALYZE_LOCALLY="${LLMDBENCH_RUN_EXPERIMENT_ANALYZE_LOCALLY:-0}"
export LLMDBENCH_RUN_WORKSPACE_DIR=${LLMDBENCH_WORKSPACE_DIR:-/workspace}
export LLMDBENCH_RUN_DATASET_DIR=${LLMDBENCH_RUN_DATASET_DIR:-$LLMDBENCH_RUN_WORKSPACE_DIR}
export LLMDBENCH_RUN_DATASET_URL=${LLMDBENCH_RUN_DATASET_URL:-}

# Control variables
export LLMDBENCH_CONTROL_CLUSTER_NAME=${LLMDBENCH_CONTROL_CLUSTER_NAME:-$(echo ${LLMDBENCH_CLUSTER_URL} | cut -d '.' -f 2)}
export LLMDBENCH_CONTROL_ENVVAR_DISPLAYED=${LLMDBENCH_CONTROL_ENVVAR_DISPLAYED:-0}
export LLMDBENCH_CONTROL_DEPENDENCIES_CHECKED=${LLMDBENCH_CONTROL_DEPENDENCIES_CHECKED:-0}
export LLMDBENCH_CONTROL_OVERRIDE_COMMAND_DISPLAYED=${LLMDBENCH_CONTROL_OVERRIDE_COMMAND_DISPLAYED:-0}
export LLMDBENCH_CONTROL_PERMISSIONS_CHECKED=${LLMDBENCH_CONTROL_PERMISSIONS_CHECKED:-0}
export LLMDBENCH_CONTROL_WARNING_DISPLAYED=${LLMDBENCH_CONTROL_WARNING_DISPLAYED:-0}
export LLMDBENCH_CONTROL_STANDUP_ALL_STEPS=${LLMDBENCH_CONTROL_STANDUP_ALL_STEPS:-0}
export LLMDBENCH_CONTROL_WAIT_TIMEOUT=${LLMDBENCH_CONTROL_WAIT_TIMEOUT:-900}
export LLMDBENCH_CONTROL_CHECK_CLUSTER_AUTHORIZATIONS=${LLMDBENCH_CONTROL_CHECK_CLUSTER_AUTHORIZATIONS:-0}
export LLMDBENCH_CONTROL_RESOURCE_LIST=${LLMDBENCH_CONTROL_RESOURCE_LIST:-deployment,httproute,service,gateway,gatewayparameters,inferencepool,inferencemodel,cm,ing,pod,job}
export LLMDBENCH_CONTROL_STEP_00_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_00_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_01_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_01_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_02_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_02_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_03_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_03_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_04_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_04_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_05_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_05_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_06_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_06_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_07_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_07_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_08_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_08_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_09_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_09_IMPLEMENTATION:-py}
export LLMDBENCH_CONTROL_STEP_10_IMPLEMENTATION=${LLMDBENCH_CONTROL_STEP_10_IMPLEMENTATION:-py}



source $LLMDBENCH_MAIN_DIR/setup/functions.sh

is_oc=$(which oc || true)
if [[ -z $is_oc ]]; then
  export LLMDBENCH_CONTROL_KCMD=${LLMDBENCH_CONTROL_KCMD:-kubectl}
else
  export LLMDBENCH_CONTROL_KCMD=${LLMDBENCH_CONTROL_KCMD:-oc}
fi

export LLMDBENCH_CONTROL_HCMD=helm
export LLMDBENCH_CONTROL_CLI_OPTS_PROCESSED=${LLMDBENCH_CONTROL_CLI_OPTS_PROCESSED:-0}

is_mac=$(uname -s | grep -i darwin || true)
if [[ ! -z $is_mac ]]
then
    export LLMDBENCH_CONTROL_DEPLOY_HOST_OS=mac
    export LLMDBENCH_BASE64_ARGS=""
  is_gsed=$(which gsed || true)
  if [[ -z ${is_gsed} ]]; then
    brew install gnu-sed
  fi
  export LLMDBENCH_CONTROL_SCMD=gsed
else
    export LLMDBENCH_CONTROL_DEPLOY_HOST_OS=linux
    export LLMDBENCH_BASE64_ARGS="-w0"
    export LLMDBENCH_CONTROL_SCMD=sed
fi

export LLMDBENCH_CONTROL_PCMD=${LLMDBENCH_CONTROL_PCMD:-python3}
is_podman=$(which podman || true)
if [[ ! -z ${is_podman} ]]; then
  export LLMDBENCH_CONTROL_CCMD=podman
else
  is_docker=$(which docker || true)
  if [[ ! -z ${is_docker} ]]; then
    export LLMDBENCH_CONTROL_CCMD=docker
  fi
fi

if [[ $LLMDBENCH_CONTROL_DEPENDENCIES_CHECKED -eq 0 ]]
then
  touch ~/.llmdbench_dependencies_checked
  deplist="$LLMDBENCH_CONTROL_SCMD $LLMDBENCH_CONTROL_PCMD $(echo $LLMDBENCH_CONTROL_KCMD | awk '{ print $1}') $(echo $LLMDBENCH_CONTROL_HCMD | awk '{ print $1}') helmfile kubectl kustomize rsync"
  for req in $deplist; do
    is_checked=$(grep "$req already installed" ~/.llmdbench_dependencies_checked || true)
    if [[ -z ${is_checked} ]]; then
      echo -n "Checking dependency \"${req}\"..."
      is_req=$(which ${req} || true)
      if [[ -z ${is_req} ]]; then
        echo "❌ Dependency \"${req}\" is missing. Please run \"$LLMDBENCH_MAIN_DIR/setup/install_deps.sh\" and try again."
        exit 1
      else
        echo "$req already installed" >> ~/.llmdbench_dependencies_checked
      fi
      echo "done"
    fi
  done
  echo
  is_helmdiff=$($LLMDBENCH_CONTROL_HCMD plugin list | grep diff || true)
  if [[ -z $is_helmdiff ]]; then
    helm plugin install https://github.com/databus23/helm-diff
  fi
  export LLMDBENCH_CONTROL_DEPENDENCIES_CHECKED=1
fi

if [[ $LLMDBENCH_CONTROL_CLI_OPTS_PROCESSED -eq 0 ]]; then
  return 0
fi

if [[ ! -z $LLMDBENCH_CLIOVERRIDE_DEPLOY_SCENARIO ]]; then
  export LLMDBENCH_DEPLOY_SCENARIO=$LLMDBENCH_CLIOVERRIDE_DEPLOY_SCENARIO
fi


export LLMDBENCH_VLLM_MODELSERVICE_MULTINODE=${LLMDBENCH_VLLM_MODELSERVICE_MULTINODE:-false}
export LLMDBENCH_VLLM_MODELSERVICE_MOUNT_MODEL_VOLUME_OVERRIDE=${LLMDBENCH_VLLM_MODELSERVICE_MOUNT_MODEL_VOLUME_OVERRIDE:-}

export LLMDBENCH_VLLM_MODELSERVICE_DECODE_REPLICAS=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_REPLICAS:-$LLMDBENCH_VLLM_COMMON_REPLICAS}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_PODANNOTATIONS=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_PODANNOTATIONS:-deployed-by:$LLMDBENCH_CONTROL_USERNAME,modelservice:llm-d-benchmark}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_ACCELERATOR_MEM_UTIL=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_ACCELERATOR_MEM_UTIL:-$LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEM_UTIL}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_DATA_PARALLELISM=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_DATA_PARALLELISM:-1}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM:-1}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_ACCELERATOR_NR=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_ACCELERATOR_NR:-auto}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_NETWORK_RESOURCE=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_NETWORK_RESOURCE:-$LLMDBENCH_VLLM_COMMON_NETWORK_RESOURCE}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_NETWORK_NR=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_NETWORK_NR:-$LLMDBENCH_VLLM_COMMON_NETWORK_NR}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_NR=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_NR:-$LLMDBENCH_VLLM_COMMON_CPU_NR}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_MEM=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_MEM:-$LLMDBENCH_VLLM_COMMON_CPU_MEM}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_SHM_MEM=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_SHM_MEM:-$LLMDBENCH_VLLM_COMMON_SHM_MEM}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EPHEMERAL_STORAGE_NR=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EPHEMERAL_STORAGE_NR:-$LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_NR}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_MODEL_COMMAND=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_MODEL_COMMAND:-vllmServe}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_ARGS=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_ARGS:-"[--disable-log-requests____--max-model-len____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN____--tensor-parallel-size____REPLACE_ENV_LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM]"}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_INFERENCE_PORT=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_INFERENCE_PORT:-${LLMDBENCH_VLLM_COMMON_INFERENCE_PORT}}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_POD_CONFIG=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_POD_CONFIG:-$LLMDBENCH_VLLM_COMMON_EXTRA_POD_CONFIG}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_CONTAINER_CONFIG=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_CONTAINER_CONFIG:-$LLMDBENCH_VLLM_COMMON_EXTRA_CONTAINER_CONFIG}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_VOLUME_MOUNTS=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_VOLUME_MOUNTS:-$LLMDBENCH_VLLM_COMMON_EXTRA_VOLUME_MOUNTS}
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_VOLUMES=${LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_VOLUMES:-$LLMDBENCH_VLLM_COMMON_EXTRA_VOLUMES}

export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_REPLICAS=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_REPLICAS:-$LLMDBENCH_VLLM_COMMON_REPLICAS}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_PODANNOTATIONS=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_PODANNOTATIONS:-deployed-by:$LLMDBENCH_CONTROL_USERNAME,modelservice:llm-d-benchmark}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_ACCELERATOR_MEM_UTIL=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_ACCELERATOR_MEM_UTIL:-$LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEM_UTIL}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_DATA_PARALLELISM=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_DATA_PARALLELISM:-1}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM:-1}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_ACCELERATOR_NR=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_ACCELERATOR_NR:-auto}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_NETWORK_RESOURCE=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_NETWORK_RESOURCE:-$LLMDBENCH_VLLM_COMMON_NETWORK_RESOURCE}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_NETWORK_NR=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_NETWORK_NR:-$LLMDBENCH_VLLM_COMMON_NETWORK_NR}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_NR=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_NR:-$LLMDBENCH_VLLM_COMMON_CPU_NR}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_MEM=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_MEM:-$LLMDBENCH_VLLM_COMMON_CPU_MEM}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_SHM_MEM=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_SHM_MEM:-$LLMDBENCH_VLLM_COMMON_SHM_MEM}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EPHEMERAL_STORAGE_NR=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EPHEMERAL_STORAGE_NR:-$LLMDBENCH_VLLM_COMMON_EPHEMERAL_STORAGE_NR}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_MODEL_COMMAND=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_MODEL_COMMAND:-vllmServe}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_ARGS=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_ARGS:-"[--disable-log-requests____--max-model-len____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN____--tensor-parallel-size____REPLACE_ENV_LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM]"}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_POD_CONFIG=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_POD_CONFIG:-$LLMDBENCH_VLLM_COMMON_EXTRA_POD_CONFIG}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_CONTAINER_CONFIG=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_CONTAINER_CONFIG:-$LLMDBENCH_VLLM_COMMON_EXTRA_CONTAINER_CONFIG}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_VOLUME_MOUNTS=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_VOLUME_MOUNTS:-$LLMDBENCH_VLLM_COMMON_EXTRA_VOLUME_MOUNTS}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_VOLUMES=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_VOLUMES:-$LLMDBENCH_VLLM_COMMON_EXTRA_VOLUMES}
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_INFERENCE_PORT=${LLMDBENCH_VLLM_MODELSERVICE_PREFILL_INFERENCE_PORT:-${LLMDBENCH_VLLM_COMMON_INFERENCE_PORT}}

if [[ ! -z $LLMDBENCH_DEPLOY_SCENARIO ]]; then
  export LLMDBENCH_DEPLOY_SCENARIO=$(echo $LLMDBENCH_DEPLOY_SCENARIO'.sh' | $LLMDBENCH_CONTROL_SCMD 's^.sh.sh^.sh^g')
  if [[ "$LLMDBENCH_DEPLOY_SCENARIO" == /* ]]; then
    export LLMDBENCH_SCENARIO_FULL_PATH=$LLMDBENCH_DEPLOY_SCENARIO
  else
    export LLMDBENCH_SCENARIO_FULL_PATH=$(find ${LLMDBENCH_MAIN_DIR}/scenarios -name $LLMDBENCH_DEPLOY_SCENARIO)
  fi
else
  export LLMDBENCH_SCENARIO_FULL_PATH="${LLMDBENCH_MAIN_DIR}/scenarios/none.sh"
  touch ${LLMDBENCH_MAIN_DIR}/scenarios/none.sh
fi

if [[ ! -z $LLMDBENCH_SCENARIO_FULL_PATH ]]; then
  source $LLMDBENCH_SCENARIO_FULL_PATH
elif [[ $LLMDBENCH_SCENARIO_FULL_PATH == "${LLMDBENCH_MAIN_DIR}/scenarios/none.sh" ]]; then
  touch ${LLMDBENCH_MAIN_DIR}/scenarios/none.sh
else
  echo "❌ Scenario file \"$LLMDBENCH_SCENARIO_FULL_PATH\" ($LLMDBENCH_DEPLOY_SCENARIO) could not be found."
  exit 1
fi

overridevarlist=$(env | grep _CLIOVERRIDE_ | cut -d '=' -f 1 || true)
if [[ -n "$overridevarlist" ]]; then
  for overridevar in $overridevarlist; do
    actualvar=$(echo "$overridevar" | sed 's/_CLIOVERRIDE//g')
    if [[ -n "${!overridevar:-}" ]]; then
      export $actualvar=${!overridevar}
      if [[ ${LLMDBENCH_CONTROL_VERBOSE} -eq 1 && ${LLMDBENCH_CONTROL_OVERRIDE_COMMAND_DISPLAYED} -eq 0 ]]; then
        echo "Environment variable $actualvar was overridden by command line options"
      fi
    fi
  done
  echo
  export LLMDBENCH_CONTROL_OVERRIDE_COMMAND_DISPLAYED=1
fi

if [[ ! -z $LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS ]]; then
  if [[ "$LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS" == /* ]]; then
    export LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS_FULL_PATH=$(echo $LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS'.yaml' | $LLMDBENCH_CONTROL_SCMD 's^.yaml.yaml^.yaml^g')
  else
    export LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS_FULL_PATH=$(echo ${LLMDBENCH_MAIN_DIR}/experiments/$LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS'.yaml' | $LLMDBENCH_CONTROL_SCMD 's^.yaml.yaml^.yaml^g')
  fi
  if [[ ! -f $LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS_FULL_PATH ]]; then
    echo "❌ Treatments (experiment) file \"$LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS_FULL_PATH\" could not be found."
    exit 1
  else
    export LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS=$LLMDBENCH_HARNESS_EXPERIMENT_TREATMENTS_FULL_PATH
  fi
fi

export LLMDBENCH_CONTROL_WORK_DIR=${LLMDBENCH_CONTROL_WORK_DIR:-$(mktemp -d -t ${LLMDBENCH_CONTROL_CLUSTER_NAME}-$(echo $0 | rev | cut -d '/' -f 1 | rev | $LLMDBENCH_CONTROL_SCMD -e 's^.sh^^g' -e 's^./^^g')XXX)}
export LLMDBENCH_CONTROL_WORK_DIR_SET=${LLMDBENCH_CONTROL_WORK_DIR_SET:-0}
export LLMDBENCH_CONTROL_WORK_DIR_BACKEDUP=${LLMDBENCH_CONTROL_WORK_DIR_BACKEDUP:-0}
export LLMDBENCH_CURRENT_STEP=${LLMDBENCH_CURRENT_STEP:-}

if [[ ! -z $LLMDBENCH_RUN_DATASET_URL ]]; then
  export LLMDBENCH_RUN_DATASET_FILE=$(echo $LLMDBENCH_RUN_DATASET_URL | rev | cut -d '/' -f 1 | rev)
fi

backup_work_dir

prepare_work_dir

if [[ ! -f $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx ]]; then
  if [[ -f ${HOME}/.kube/config-${LLMDBENCH_CONTROL_CLUSTER_NAME} ]]; then
    export LLMDBENCH_CONTROL_KCMD="oc --kubeconfig ${HOME}/.kube/config-${LLMDBENCH_CONTROL_CLUSTER_NAME}"
    export LLMDBENCH_CONTROL_HCMD="helm --kubeconfig ${HOME}/.kube/config-${LLMDBENCH_CONTROL_CLUSTER_NAME}"
    cp -f ${HOME}/.kube/config-${LLMDBENCH_CONTROL_CLUSTER_NAME} $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx
    export LLMDBENCH_CONTROL_REMOTE_KUBECONFIG_FILENAME=config-${LLMDBENCH_CONTROL_CLUSTER_NAME}
  elif [[ -z $LLMDBENCH_CLUSTER_URL || $LLMDBENCH_CLUSTER_URL == "auto" ]]; then
    export LLMDBENCH_CONTROL_KCMD=$(echo $LLMDBENCH_CONTROL_KCMD | $LLMDBENCH_CONTROL_SCMD "s^--kubeconfig $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx^^g")
    current_context=$(${LLMDBENCH_CONTROL_KCMD} config view -o json | jq -r '."current-context"' || true)
    if [[ -z ${current_context} ]]; then
      echo "ERROR: unable to locate current context (LLMDBENCH_CLUSTER_URL=$LLMDBENCH_CLUSTER_URL)"
      exit 1
    else
      ${LLMDBENCH_CONTROL_KCMD} config view --minify --flatten --raw --context=${current_context} > $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx
    fi
    export LLMDBENCH_CONTROL_CLUSTER_NAME=$(echo $current_context | cut -d '/' -f 2 | cut -d '-' -f 2)
    export LLMDBENCH_CONTROL_CLUSTER_NAMESPACE=$(echo $current_context | cut -d '/' -f 1)
    if [[ $LLMDBENCH_CONTROL_WARNING_DISPLAYED -eq 0 ]]; then
      echo ""
      echo "WARNING: environment variable LLMDBENCH_CLUSTER_URL=$LLMDBENCH_CLUSTER_URL. Will attempt to use current context \"${current_context}\"."
      echo ""
      export LLMDBENCH_CONTROL_WARNING_DISPLAYED=1
      sleep 5
    fi
    export LLMDBENCH_CONTROL_REMOTE_KUBECONFIG_FILENAME=config
  else
    current_context=$(${LLMDBENCH_CONTROL_KCMD} config view -o json | jq -r '."current-context"' || true)
    if [[ -z ${current_context} ]]; then
      echo "ERROR: unable to locate current context"
      exit 1
    else
      ${LLMDBENCH_CONTROL_KCMD} config view --minify --flatten --raw --context=${current_context} > $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx
    fi

    export LLMDBENCH_CONTROL_CLUSTER_NAME=$(echo $current_context | cut -d '/' -f 2 | cut -d '-' -f 2)
    current_url=$(echo $current_context | cut -d '/' -f 2 | cut -d ':' -f 1 | $LLMDBENCH_CONTROL_SCMD "s^-^.^g")
    target_url=$(echo $LLMDBENCH_CLUSTER_URL | cut -d '/' -f 3 | $LLMDBENCH_CONTROL_SCMD "s^-^.^g")
    if [[ $current_url != $target_url ]]; then
      ${LLMDBENCH_CONTROL_KCMD} login --token="${LLMDBENCH_CLUSTER_TOKEN}" --server="${LLMDBENCH_CLUSTER_URL}:6443"
    fi

    if [[ $LLMDBENCH_CONTROL_CLUSTER_NAMESPACE != $LLMDBENCH_VLLM_COMMON_NAMESPACE ]]; then
      namespace_exists=$(${LLMDBENCH_CONTROL_KCMD} get namespaces | grep $LLMDBENCH_VLLM_COMMON_NAMESPACE || true)
      if [[ ! -z $namespace_exists ]]; then
        ${LLMDBENCH_CONTROL_KCMD} project $LLMDBENCH_VLLM_COMMON_NAMESPACE
      fi
    fi
    export LLMDBENCH_CONTROL_REMOTE_KUBECONFIG_FILENAME=config
  fi
fi
if [[ -f $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx ]]; then
  export LLMDBENCH_CONTROL_KCMD="oc --kubeconfig $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx"
  export LLMDBENCH_CONTROL_HCMD="helm --kubeconfig $LLMDBENCH_CONTROL_WORK_DIR/environment/context.ctx"
fi

export LLMDBENCH_CONTROL_CLUSTER_NAMESPACE=$(${LLMDBENCH_CONTROL_KCMD} config view --minify --output 'jsonpath={..namespace}')

export LLMDBENCH_CONTROL_DEPLOY_IS_OPENSHIFT=${LLMDBENCH_CONTROL_DEPLOY_IS_OPENSHIFT:-0}
is_ocp=$($LLMDBENCH_CONTROL_KCMD api-resources 2>&1 | grep 'route.openshift.io' || true)
if [[ ! -z ${is_ocp} ]]; then
  export LLMDBENCH_CONTROL_DEPLOY_IS_OPENSHIFT=1
else
  export LLMDBENCH_CONTROL_KCMD=$(echo $LLMDBENCH_CONTROL_KCMD | $LLMDBENCH_CONTROL_SCMD 's^oc ^kubectl ^g')
fi

export LLMDBENCH_USER_IS_ADMIN=0
if [[ $LLMDBENCH_CONTROL_DEPLOY_IS_OPENSHIFT -eq 1 ]]; then
  admin_user=$($LLMDBENCH_CONTROL_KCMD get clusterrolebindings -o json | jq '.items[] | select(.roleRef.name=="cluster-admin")' | jq '.subjects[0].name'  | grep $($LLMDBENCH_CONTROL_KCMD whoami) || true)
  if [[ ! -z ${admin_user} || $($LLMDBENCH_CONTROL_KCMD whoami) == "system:admin" ]]; then
    export LLMDBENCH_USER_IS_ADMIN=1
  fi
else
  not_admin=$($LLMDBENCH_CONTROL_KCMD get crds 2>&1 | grep -i Forbidden || true)
  if [[ -z ${not_admin} ]]; then
    export LLMDBENCH_USER_IS_ADMIN=1
    is_ns=$($LLMDBENCH_CONTROL_KCMD get namespace -o name| grep -E "namespace/${LLMDBENCH_VLLM_COMMON_NAMESPACE}$" || true)
    if [[ ! -z ${is_ns} ]]; then
      export LLMDBENCH_CONTROL_PROXY_UID=$($LLMDBENCH_CONTROL_KCMD get namespace ${LLMDBENCH_VLLM_COMMON_NAMESPACE} -o json | jq -e -r '.metadata.annotations["openshift.io/sa.scc.uid-range"]' | perl -F'/' -lane 'print $F[0]+1');
    fi
  fi
fi

export LLMDBENCH_CONTROL_DEPLOY_IS_MINIKUBE=${LLMDBENCH_CONTROL_DEPLOY_IS_MINIKUBE:-0}
has_minikube=$($LLMDBENCH_CONTROL_KCMD get pods -n kube-system 2>&1 | grep 'etcd-minikube' || true)
if [[ ! -z ${has_minikube} ]]; then
  export LLMDBENCH_CONTROL_DEPLOY_IS_MINIKUBE=1
fi

export LLMDBENCH_CONTROL_DEPLOY_IS_KIND=${LLMDBENCH_CONTROL_DEPLOY_IS_KIND:-0}
has_kind=$($LLMDBENCH_CONTROL_KCMD get pods -n kube-system 2>&1 | grep 'kind-cluster-control-plane' || true)
if [[ ! -z ${has_kind} ]]; then
  export LLMDBENCH_CONTROL_DEPLOY_IS_KIND=1
fi

for mt in standalone modelservice; do
  is_env=$(echo $LLMDBENCH_DEPLOY_METHODS | grep $mt || true)
  if [[ -z $is_env ]]; then
    export LLMDBENCH_CONTROL_ENVIRONMENT_TYPE_$(echo $mt | tr '[:lower:]' '[:upper:]')_ACTIVE=0
  else
    export LLMDBENCH_CONTROL_ENVIRONMENT_TYPE_$(echo $mt | tr '[:lower:]' '[:upper:]')_ACTIVE=1
  fi
done

if [[ $LLMDBENCH_CONTROL_PERMISSIONS_CHECKED -eq 0 && ${LLMDBENCH_CONTROL_CHECK_CLUSTER_AUTHORIZATIONS} -ne 0 ]]; then
  for resource in namespace ${LLMDBENCH_CONTROL_RESOURCE_LIST//,/ }; do
    ra=$($LLMDBENCH_CONTROL_KCMD --namespace $LLMDBENCH_VLLM_COMMON_NAMESPACE auth can-i '*' $resource 2>&1 | grep yes || true)
    if [[ -z ${ra} ]]
    then
      echo "ERROR: the current user cannot operate over the resource \"${resource}\""
      exit 1
    fi

    ra=$($LLMDBENCH_CONTROL_KCMD --namespace $LLMDBENCH_VLLM_COMMON_NAMESPACE auth can-i patch serviceaccount 2>&1 | grep yes || true)
    if [[ -z ${ra} ]]
    then
      echo "ERROR: the current user cannot operate patch serviceaccount\""
      exit 1
    fi
    export LLMDBENCH_CONTROL_PERMISSIONS_CHECKED=1
  done
fi

if [[ $LLMDBENCH_CONTROL_CALLER == "run.sh" ]]; then
  if [[ -z $LLMDBENCH_HF_TOKEN ]]; then
    announce "🔍 Environment variable \"LLMDBENCH_HF_TOKEN\" not set, attempting to extract it from secret \"LLMDBENCH_VLLM_COMMON_HF_TOKEN_NAME=${LLMDBENCH_VLLM_COMMON_HF_TOKEN_NAME}\"..."
    LLMDBENCH_HF_TOKEN=$($LLMDBENCH_CONTROL_KCMD --namespace $LLMDBENCH_VLLM_COMMON_NAMESPACE get secrets ${LLMDBENCH_VLLM_COMMON_HF_TOKEN_NAME} -o jsonpath='{.data.*}' | base64 -d | grep ^hf_ || true)
  fi
fi

export HF_TOKEN=${HF_TOKEN:-$LLMDBENCH_HF_TOKEN}

if ! echo ${LLMDBENCH_CONTROL_CALLER} | grep -iq "teardown"; then
  if is_hf_model_gated "${LLMDBENCH_DEPLOY_MODEL_LIST}"; then
    if [[ -z ${HF_TOKEN} ]]; then
      announce "❌ Hugging Face Token is empty but attempted to use gated model \"${LLMDBENCH_DEPLOY_MODEL_LIST}\""
      exit 1
    fi

    if user_has_hf_model_access "${LLMDBENCH_DEPLOY_MODEL_LIST}" "${HF_TOKEN}"; then
        announce "✅ Verified access to gated model \"${LLMDBENCH_DEPLOY_MODEL_LIST}\" is authorized."
    else
        rc=$?
        if [[ ${rc} -eq 1 ]]; then
            announce "❌ Unauthorized access to gated model \"${LLMDBENCH_DEPLOY_MODEL_LIST}\"."
            exit 1
        else
            announce "❌ Error: Request to check authorized access to \"${LLMDBENCH_DEPLOY_MODEL_LIST}\" failed."
            exit 1
        fi
    fi
  else
    announce "✅ Verified the model \"${LLMDBENCH_DEPLOY_MODEL_LIST}\" is not gated, access is authorized by default"
  fi
fi


export LLMDBENCH_CONTROL_DEPLOY_HOST_SHELL=${SHELL:5}
