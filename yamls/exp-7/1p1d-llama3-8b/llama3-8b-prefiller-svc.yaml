apiVersion: v1
kind: Service
metadata:
  name: llama3-8b-prefiller
  namespace: vllm-prod
spec:
  ports:
    - port: 8000
      targetPort: 8000
      protocol: TCP
  selector:
    app: llama3-8b-prefiller
    llm-d.ai/inferenceServing: "true"
    llm-d.ai/model: "llama3-8b"
    llm-d.ai/role: "prefill" 