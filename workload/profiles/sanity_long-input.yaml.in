# LMBenchmark Workload Specification Example
model_name: "REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL"  # Model identifier
scenarios: "long-input"  # Scenarios to run (all, or sharegpt, long-input, short-input)
qps_values: "0.5 1.3"  # Space-separated list of QPS values to test
image: "REPLACE_ENV_LLMDBENCH_FMPERF_CONTAINER_IMAGE"  # Container image to use
service_account: "REPLACE_ENV_LLMDBENCH_CLUSTER_SERVICE_ACCOUNT"  # Service account to use for the job
num_users_warmup: "REPLACE_NUM_USERS_DURING_WARMUP"
num_users: "REPLACE_NUM_USERS_FOR_SYNTHETIC_PREFIX_REUSE"
num_rounds: "REPLACE_NUM_OF_ROUNDS_OF_USER_PREFIX_REUSE"
system_prompt: "REPLACE_SYSTEM_PROMPT_LENGTH"
chat_history: "REPLACE_CHAT_HISTORY_LENGTH"
answer_len: "REPLACE_ANSWER_LENGTH"
init_user_id: "REPLACE_INITIAL_USER_ID"
test_duration: "REPLACE_THE_DURATION_OF_BENCHMARKING_PERIOD_IN_SECONDS"
